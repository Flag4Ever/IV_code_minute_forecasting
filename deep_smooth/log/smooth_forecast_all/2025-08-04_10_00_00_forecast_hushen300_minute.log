==========================================
训练开始时间: 2025-10-18 15:12:37
分钟: 2025-08-04 10:00:00 | 划分: forecast | 设备: cuda
标记列: train_flag_inter
==========================================
使用设备: CUDA (NVIDIA GeForce RTX 4090)
加载数据: ../data/hushen300_minute/hushen300_minute.csv
筛选分钟: 2025-08-04 10:00:00
筛选后数据行数: 120
按照 train_flag_inter=1 筛选后数据行数: 120
使用 torch.compile 优化模型 (设备: cuda)
/home/douxueli/miniconda3/envs/iv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
开始训练，总轮数: 10000, Restart次数: 4
Saved! Epoch 1 Loss:  0.29955;lr: 0.01000
Saved! Epoch 2 Loss:  0.15877;lr: 0.01000
Saved! Epoch 3 Loss:  0.12392;lr: 0.01000
Saved! Epoch 6 Loss:  0.11499;lr: 0.01000
Saved! Epoch 7 Loss:  0.10528;lr: 0.01000
Saved! Epoch 9 Loss:  0.09147;lr: 0.01000
Saved! Epoch 12 Loss:  0.08580;lr: 0.01000
Saved! Epoch 15 Loss:  0.08082;lr: 0.01000
Saved! Epoch 17 Loss:  0.07581;lr: 0.01000
Saved! Epoch 20 Loss:  0.07340;lr: 0.01000
Saved! Epoch 42 Loss:  0.07255;lr: 0.01000
Saved! Epoch 46 Loss:  0.07153;lr: 0.01000
Saved! Epoch 52 Loss:  0.07012;lr: 0.01000
Saved! Epoch 59 Loss:  0.06929;lr: 0.01000
Saved! Epoch 67 Loss:  0.06796;lr: 0.01000
Saved! Epoch 80 Loss:  0.06680;lr: 0.01000
Saved! Epoch 85 Loss:  0.06589;lr: 0.01000
Saved! Epoch 90 Loss:  0.06506;lr: 0.01000
Saved! Epoch 103 Loss:  0.06399;lr: 0.01000
Saved! Epoch 116 Loss:  0.06317;lr: 0.01000
Saved! Epoch 141 Loss:  0.06247;lr: 0.01000
Saved! Epoch 185 Loss:  0.06181;lr: 0.01000
Saved! Epoch 284 Loss:  0.06110;lr: 0.01000
Saved! Epoch 417 Loss:  0.06035;lr: 0.01000
Saved! Epoch 1024 Loss:  0.05974;lr: 0.00500
Saved! Epoch 1696 Loss:  0.05914;lr: 0.00250
Saved! Epoch 1910 Loss:  0.05853;lr: 0.00250
Saved! Epoch 2000 Loss:  0.05815;lr: 0.00250
Saved! Epoch 2008 Loss:  0.05792;lr: 0.00250
Saved! Epoch 2070 Loss:  0.05733;lr: 0.00250
Saved! Epoch 2098 Loss:  0.05674;lr: 0.00250
Saved! Epoch 2130 Loss:  0.05616;lr: 0.00250
Saved! Epoch 2150 Loss:  0.05556;lr: 0.00250
Saved! Epoch 2167 Loss:  0.05500;lr: 0.00250
Saved! Epoch 2182 Loss:  0.05442;lr: 0.00250
Saved! Epoch 2198 Loss:  0.05387;lr: 0.00250
Saved! Epoch 2209 Loss:  0.05328;lr: 0.00250
Saved! Epoch 2222 Loss:  0.05274;lr: 0.00250
Saved! Epoch 2233 Loss:  0.05218;lr: 0.00250
Saved! Epoch 2246 Loss:  0.05161;lr: 0.00250
Saved! Epoch 2257 Loss:  0.05108;lr: 0.00250
Saved! Epoch 2265 Loss:  0.05047;lr: 0.00250
Saved! Epoch 2278 Loss:  0.04981;lr: 0.00250
Saved! Epoch 2289 Loss:  0.04928;lr: 0.00250
Saved! Epoch 2298 Loss:  0.04875;lr: 0.00250
Saved! Epoch 2306 Loss:  0.04826;lr: 0.00250
Saved! Epoch 2314 Loss:  0.04775;lr: 0.00250
Saved! Epoch 2323 Loss:  0.04726;lr: 0.00250
Saved! Epoch 2335 Loss:  0.04677;lr: 0.00250
Saved! Epoch 2347 Loss:  0.04629;lr: 0.00250
Saved! Epoch 2365 Loss:  0.04566;lr: 0.00250
Saved! Epoch 2390 Loss:  0.04519;lr: 0.00250
Saved! Epoch 2417 Loss:  0.04474;lr: 0.00250
Saved! Epoch 2452 Loss:  0.04428;lr: 0.00250
Saved! Epoch 2494 Loss:  0.04383;lr: 0.00250
Saved! Epoch 2538 Loss:  0.04333;lr: 0.00250
Saved! Epoch 2591 Loss:  0.04287;lr: 0.00250
Saved! Epoch 2640 Loss:  0.04240;lr: 0.00250
Saved! Epoch 2690 Loss:  0.04196;lr: 0.00250
Saved! Epoch 2736 Loss:  0.04149;lr: 0.00250
Saved! Epoch 2776 Loss:  0.04106;lr: 0.00250
Saved! Epoch 2813 Loss:  0.04061;lr: 0.00250
Saved! Epoch 2851 Loss:  0.04018;lr: 0.00250
Saved! Epoch 2898 Loss:  0.03978;lr: 0.00250
Saved! Epoch 2949 Loss:  0.03937;lr: 0.00250
Saved! Epoch 2996 Loss:  0.03896;lr: 0.00250
Saved! Epoch 3064 Loss:  0.03855;lr: 0.00250
Saved! Epoch 3123 Loss:  0.03815;lr: 0.00250
Saved! Epoch 3174 Loss:  0.03775;lr: 0.00250
Saved! Epoch 3237 Loss:  0.03732;lr: 0.00250
Saved! Epoch 3311 Loss:  0.03694;lr: 0.00250
Saved! Epoch 3378 Loss:  0.03649;lr: 0.00250
Saved! Epoch 3445 Loss:  0.03610;lr: 0.00250
Saved! Epoch 3548 Loss:  0.03571;lr: 0.00250
Saved! Epoch 3607 Loss:  0.03531;lr: 0.00250
Saved! Epoch 3680 Loss:  0.03495;lr: 0.00250
Saved! Epoch 3793 Loss:  0.03455;lr: 0.00250
Saved! Epoch 3920 Loss:  0.03418;lr: 0.00250
Saved! Epoch 4000 Loss:  0.03402;lr: 0.00250
Saved! Epoch 4010 Loss:  0.03384;lr: 0.00250
Saved! Epoch 4155 Loss:  0.03350;lr: 0.00250
Saved! Epoch 4341 Loss:  0.03312;lr: 0.00250
Saved! Epoch 4552 Loss:  0.03277;lr: 0.00250
Saved! Epoch 4825 Loss:  0.03241;lr: 0.00250
Saved! Epoch 5143 Loss:  0.03206;lr: 0.00250
Saved! Epoch 5292 Loss:  0.03173;lr: 0.00250
Saved! Epoch 5602 Loss:  0.03138;lr: 0.00250
Saved! Epoch 5875 Loss:  0.03106;lr: 0.00250
Saved! Epoch 6000 Loss:  0.03102;lr: 0.00250
Saved! Epoch 6135 Loss:  0.03075;lr: 0.00250
Saved! Epoch 6309 Loss:  0.03042;lr: 0.00250
Saved! Epoch 6585 Loss:  0.03011;lr: 0.00250
Saved! Epoch 6919 Loss:  0.02978;lr: 0.00250
Saved! Epoch 7160 Loss:  0.02949;lr: 0.00250
Saved! Epoch 7421 Loss:  0.02918;lr: 0.00250
Saved! Epoch 7741 Loss:  0.02885;lr: 0.00250
Saved! Epoch 8000 Loss:  0.02924;lr: 0.00250
Saved! Epoch 8024 Loss:  0.02854;lr: 0.00250
Saved! Epoch 8306 Loss:  0.02820;lr: 0.00250
Saved! Epoch 8620 Loss:  0.02791;lr: 0.00250
Saved! Epoch 8953 Loss:  0.02761;lr: 0.00250
Saved! Epoch 9250 Loss:  0.02728;lr: 0.00250
Saved! Epoch 9565 Loss:  0.02700;lr: 0.00250
Saved! Epoch 9989 Loss:  0.02670;lr: 0.00250
Saved! Epoch 10000 Loss:  0.02696;lr: 0.00250

训练完成! 分钟: 2025-08-04 10:00:00, 划分方式: forecast

==========================================
训练结束时间: 2025-10-18 15:14:23
==========================================
