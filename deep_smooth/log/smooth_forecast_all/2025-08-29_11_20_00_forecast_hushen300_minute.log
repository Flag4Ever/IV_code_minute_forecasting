==========================================
训练开始时间: 2025-10-18 19:04:28
分钟: 2025-08-29 11:20:00 | 划分: forecast | 设备: cuda
标记列: train_flag_inter
==========================================
使用设备: CUDA (NVIDIA GeForce RTX 4090)
加载数据: ../data/hushen300_minute/hushen300_minute.csv
筛选分钟: 2025-08-29 11:20:00
筛选后数据行数: 146
按照 train_flag_inter=1 筛选后数据行数: 146
使用 torch.compile 优化模型 (设备: cuda)
/home/douxueli/miniconda3/envs/iv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
开始训练，总轮数: 10000, Restart次数: 4
Saved! Epoch 1 Loss:  0.53194;lr: 0.01000
Saved! Epoch 2 Loss:  0.18479;lr: 0.01000
Saved! Epoch 6 Loss:  0.18008;lr: 0.01000
Saved! Epoch 10 Loss:  0.17415;lr: 0.01000
Saved! Epoch 16 Loss:  0.16341;lr: 0.01000
Saved! Epoch 20 Loss:  0.15663;lr: 0.01000
Saved! Epoch 25 Loss:  0.14966;lr: 0.01000
Saved! Epoch 26 Loss:  0.14520;lr: 0.01000
Saved! Epoch 29 Loss:  0.14129;lr: 0.01000
Saved! Epoch 33 Loss:  0.13820;lr: 0.01000
Saved! Epoch 34 Loss:  0.13521;lr: 0.01000
Saved! Epoch 38 Loss:  0.13240;lr: 0.01000
Saved! Epoch 42 Loss:  0.13059;lr: 0.01000
Saved! Epoch 43 Loss:  0.12913;lr: 0.01000
Saved! Epoch 46 Loss:  0.12738;lr: 0.01000
Saved! Epoch 47 Loss:  0.12587;lr: 0.01000
Saved! Epoch 49 Loss:  0.12457;lr: 0.01000
Saved! Epoch 57 Loss:  0.12283;lr: 0.01000
Saved! Epoch 60 Loss:  0.12114;lr: 0.01000
Saved! Epoch 67 Loss:  0.11950;lr: 0.01000
Saved! Epoch 70 Loss:  0.11824;lr: 0.01000
Saved! Epoch 73 Loss:  0.11652;lr: 0.01000
Saved! Epoch 75 Loss:  0.11481;lr: 0.01000
Saved! Epoch 78 Loss:  0.11284;lr: 0.01000
Saved! Epoch 79 Loss:  0.11129;lr: 0.01000
Saved! Epoch 81 Loss:  0.10969;lr: 0.01000
Saved! Epoch 95 Loss:  0.10839;lr: 0.01000
Saved! Epoch 121 Loss:  0.10710;lr: 0.01000
Saved! Epoch 165 Loss:  0.10591;lr: 0.01000
Saved! Epoch 203 Loss:  0.10477;lr: 0.01000
Saved! Epoch 237 Loss:  0.10367;lr: 0.01000
Saved! Epoch 253 Loss:  0.10253;lr: 0.01000
Saved! Epoch 268 Loss:  0.10135;lr: 0.01000
Saved! Epoch 286 Loss:  0.10026;lr: 0.01000
Saved! Epoch 304 Loss:  0.09849;lr: 0.01000
Saved! Epoch 322 Loss:  0.09741;lr: 0.01000
Saved! Epoch 343 Loss:  0.09612;lr: 0.01000
Saved! Epoch 357 Loss:  0.09480;lr: 0.01000
Saved! Epoch 361 Loss:  0.09375;lr: 0.01000
Saved! Epoch 368 Loss:  0.09276;lr: 0.01000
Saved! Epoch 374 Loss:  0.09142;lr: 0.01000
Saved! Epoch 380 Loss:  0.09029;lr: 0.01000
Saved! Epoch 384 Loss:  0.08938;lr: 0.01000
Saved! Epoch 387 Loss:  0.08845;lr: 0.01000
Saved! Epoch 395 Loss:  0.08676;lr: 0.01000
Saved! Epoch 399 Loss:  0.08538;lr: 0.01000
Saved! Epoch 404 Loss:  0.08400;lr: 0.01000
Saved! Epoch 409 Loss:  0.08299;lr: 0.01000
Saved! Epoch 411 Loss:  0.08204;lr: 0.01000
Saved! Epoch 416 Loss:  0.08101;lr: 0.01000
Saved! Epoch 423 Loss:  0.07940;lr: 0.01000
Saved! Epoch 441 Loss:  0.07799;lr: 0.01000
Saved! Epoch 446 Loss:  0.07653;lr: 0.01000
Saved! Epoch 459 Loss:  0.07463;lr: 0.01000
Saved! Epoch 478 Loss:  0.07355;lr: 0.01000
Saved! Epoch 484 Loss:  0.07278;lr: 0.01000
Saved! Epoch 522 Loss:  0.07164;lr: 0.01000
Saved! Epoch 565 Loss:  0.07050;lr: 0.01000
Saved! Epoch 595 Loss:  0.06969;lr: 0.01000
Saved! Epoch 633 Loss:  0.06884;lr: 0.01000
Saved! Epoch 674 Loss:  0.06806;lr: 0.01000
Saved! Epoch 726 Loss:  0.06712;lr: 0.01000
Saved! Epoch 758 Loss:  0.06645;lr: 0.01000
Saved! Epoch 797 Loss:  0.06568;lr: 0.01000
Saved! Epoch 845 Loss:  0.06486;lr: 0.01000
Saved! Epoch 880 Loss:  0.06406;lr: 0.01000
Saved! Epoch 920 Loss:  0.06333;lr: 0.01000
Saved! Epoch 948 Loss:  0.06262;lr: 0.01000
Saved! Epoch 1001 Loss:  0.06189;lr: 0.01000
Saved! Epoch 1049 Loss:  0.06110;lr: 0.01000
Saved! Epoch 1118 Loss:  0.06031;lr: 0.01000
Saved! Epoch 1144 Loss:  0.05967;lr: 0.01000
Saved! Epoch 1203 Loss:  0.05903;lr: 0.01000
Saved! Epoch 1271 Loss:  0.05823;lr: 0.01000
Saved! Epoch 1347 Loss:  0.05744;lr: 0.01000
Saved! Epoch 1428 Loss:  0.05685;lr: 0.01000
Saved! Epoch 1490 Loss:  0.05626;lr: 0.01000
Saved! Epoch 1594 Loss:  0.05544;lr: 0.01000
Saved! Epoch 1684 Loss:  0.05486;lr: 0.01000
Saved! Epoch 1753 Loss:  0.05407;lr: 0.01000
Saved! Epoch 1857 Loss:  0.05339;lr: 0.01000
Saved! Epoch 1953 Loss:  0.05285;lr: 0.01000
Saved! Epoch 2000 Loss:  0.05569;lr: 0.01000
Saved! Epoch 2025 Loss:  0.05217;lr: 0.01000
Saved! Epoch 2082 Loss:  0.05151;lr: 0.01000
Saved! Epoch 2216 Loss:  0.05072;lr: 0.01000
Saved! Epoch 2263 Loss:  0.04995;lr: 0.01000
Saved! Epoch 2406 Loss:  0.04894;lr: 0.01000
Saved! Epoch 2484 Loss:  0.04825;lr: 0.01000
Saved! Epoch 2532 Loss:  0.04770;lr: 0.01000
Saved! Epoch 2612 Loss:  0.04686;lr: 0.01000
Saved! Epoch 2683 Loss:  0.04634;lr: 0.01000
Saved! Epoch 2709 Loss:  0.04580;lr: 0.01000
Saved! Epoch 2782 Loss:  0.04515;lr: 0.01000
Saved! Epoch 2892 Loss:  0.04468;lr: 0.01000
Saved! Epoch 2989 Loss:  0.04419;lr: 0.01000
Saved! Epoch 3074 Loss:  0.04361;lr: 0.01000
Saved! Epoch 3231 Loss:  0.04292;lr: 0.01000
Saved! Epoch 3389 Loss:  0.04243;lr: 0.01000
Saved! Epoch 3628 Loss:  0.04197;lr: 0.01000
Saved! Epoch 3811 Loss:  0.04142;lr: 0.01000
Saved! Epoch 4000 Loss:  0.04414;lr: 0.01000
Saved! Epoch 4314 Loss:  0.04098;lr: 0.00500
Saved! Epoch 4506 Loss:  0.04057;lr: 0.00500
Saved! Epoch 5247 Loss:  0.04016;lr: 0.00250
Saved! Epoch 6000 Loss:  0.03994;lr: 0.00125
Saved! Epoch 7090 Loss:  0.03976;lr: 0.00031
Saved! Epoch 8000 Loss:  0.03972;lr: 0.00016
Restart!Epoch 7090 Loss:  0.03968;lr: 0.01000
Saved! Epoch 8000 Loss:  0.03999;lr: 0.00500
Saved! Epoch 8121 Loss:  0.03934;lr: 0.00250
Saved! Epoch 8995 Loss:  0.03893;lr: 0.00125
Saved! Epoch 10000 Loss:  0.03874;lr: 0.00031

训练完成! 分钟: 2025-08-29 11:20:00, 划分方式: forecast

==========================================
训练结束时间: 2025-10-18 19:06:28
==========================================
