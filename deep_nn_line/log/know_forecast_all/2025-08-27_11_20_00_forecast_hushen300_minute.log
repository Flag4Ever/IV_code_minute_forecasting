==========================================
训练开始时间: 2025-10-19 09:19:49
分钟: 2025-08-27 11:20:00 | 划分: forecast | 设备: cuda
标记列: train_flag_inter
==========================================
加载数据: ../data/hushen300_minute/hushen300_minute.csv
筛选分钟: 2025-08-27 11:20:00
筛选后数据行数: 146
按照 train_flag_inter=1 筛选后数据行数: 146
加载初始化模型: ./checkpoint/know_forecast_all/hushen300_minute_forecast_clear/init_model/seed_1234_0.1_lr_0.001_gen_lr_0.001_w_d_0.0_best_model.pth
使用 torch.compile 优化模型 (设备: cuda)
/home/douxueli/miniconda3/envs/iv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
/home/douxueli/miniconda3/envs/iv/lib/python3.11/site-packages/torch/_inductor/compile_fx.py:140: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/home/douxueli/miniconda3/envs/iv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Glow模型使用 CUDA
加载Glow模型: ../glow_nn_line/glow_nn_svi_2/model_500000.pt
使用 torch.compile 优化 Glow 模型
开始训练，总轮数: 20000, 第一阶段: 0
Save!Epoch 1 Loss: -0.11529;Gen: -3.04888;fit arb:  0.18959;lr: 0.00100; no_improve: 0
Save!Epoch 2 Loss: -0.16984;Gen: -3.26616;fit arb:  0.15678;lr: 0.00100; no_improve: 0
Save!Epoch 3 Loss: -0.19940;Gen: -3.38597;fit arb:  0.13919;lr: 0.00100; no_improve: 0
Save!Epoch 4 Loss: -0.20682;Gen: -3.35648;fit arb:  0.12883;lr: 0.00100; no_improve: 0
Save!Epoch 5 Loss: -0.22277;Gen: -3.44028;fit arb:  0.12126;lr: 0.00100; no_improve: 0
Save!Epoch 9 Loss: -0.24595;Gen: -3.60405;fit arb:  0.11445;lr: 0.00100; no_improve: 3
Save!Epoch 10 Loss: -0.25855;Gen: -3.55808;fit arb:  0.09726;lr: 0.00100; no_improve: 0
Save!Epoch 11 Loss: -0.28729;Gen: -3.68175;fit arb:  0.08089;lr: 0.00100; no_improve: 0
Save!Epoch 12 Loss: -0.29193;Gen: -3.66928;fit arb:  0.07500;lr: 0.00100; no_improve: 0
Save!Epoch 30 Loss: -0.31151;Gen: -3.82710;fit arb:  0.07120;lr: 0.00100; no_improve: 17
Save!Epoch 31 Loss: -0.32733;Gen: -3.85899;fit arb:  0.05857;lr: 0.00100; no_improve: 0
Save!Epoch 42 Loss: -0.32201;Gen: -3.79292;fit arb:  0.05728;lr: 0.00100; no_improve: 10
Save!Epoch 60 Loss: -0.31447;Gen: -3.67740;fit arb:  0.05327;lr: 0.00100; no_improve: 17
Save!Epoch 61 Loss: -0.32000;Gen: -3.64492;fit arb:  0.04450;lr: 0.00100; no_improve: 0
Save!Epoch 70 Loss: -0.33584;Gen: -3.79291;fit arb:  0.04345;lr: 0.00100; no_improve: 8
Save!Epoch 138 Loss: -0.34021;Gen: -3.82718;fit arb:  0.04251;lr: 0.00100; no_improve: 67
Epoch 1000 Loss: -0.32993;Gen: -3.82500;fit arb:  0.05257;lr: 0.00050;no_improve: 862
Save!Epoch 1336 Loss: -0.34430;Gen: -3.84091;fit arb:  0.03979;lr: 0.00050; no_improve: 1197
Save!Epoch 1625 Loss: -0.35211;Gen: -3.90607;fit arb:  0.03850;lr: 0.00050; no_improve: 288
Save!Epoch 1692 Loss: -0.35071;Gen: -3.88519;fit arb:  0.03781;lr: 0.00050; no_improve: 66
Save!Epoch 1976 Loss: -0.34870;Gen: -3.85574;fit arb:  0.03687;lr: 0.00050; no_improve: 283
Epoch 2000 Loss: -0.33861;Gen: -3.84004;fit arb:  0.04539;lr: 0.00050;no_improve: 24
Save!Epoch 2026 Loss: -0.34697;Gen: -3.81989;fit arb:  0.03502;lr: 0.00050; no_improve: 49
Save!Epoch 2323 Loss: -0.35445;Gen: -3.89016;fit arb:  0.03457;lr: 0.00050; no_improve: 296
Save!Epoch 2372 Loss: -0.35292;Gen: -3.86859;fit arb:  0.03394;lr: 0.00050; no_improve: 48
Save!Epoch 2620 Loss: -0.35396;Gen: -3.86032;fit arb:  0.03208;lr: 0.00050; no_improve: 247
Save!Epoch 2737 Loss: -0.36067;Gen: -3.91588;fit arb:  0.03092;lr: 0.00050; no_improve: 116
Save!Epoch 2854 Loss: -0.36021;Gen: -3.89655;fit arb:  0.02944;lr: 0.00050; no_improve: 116
Save!Epoch 2904 Loss: -0.35593;Gen: -3.84605;fit arb:  0.02868;lr: 0.00050; no_improve: 49
Epoch 3000 Loss: -0.33477;Gen: -3.87684;fit arb:  0.05291;lr: 0.00050;no_improve: 96
Save!Epoch 3524 Loss: -0.35907;Gen: -3.86115;fit arb:  0.02705;lr: 0.00050; no_improve: 619
Epoch 4000 Loss: -0.35812;Gen: -3.91910;fit arb:  0.03379;lr: 0.00050;no_improve: 476
Epoch 5000 Loss: -0.35610;Gen: -3.89107;fit arb:  0.03301;lr: 0.00050;no_improve: 1476
Epoch 6000 Loss: -0.34839;Gen: -3.91560;fit arb:  0.04317;lr: 0.00050;no_improve: 2476
Epoch 7000 Loss: -0.33930;Gen: -3.86652;fit arb:  0.04736;lr: 0.00050;no_improve: 3476
Restart!Epoch 7524 Loss: -0.34783;Gen: -3.79820;fit arb:  0.03199;lr: 0.00100;no_improve: 0
Epoch 8000 Loss: -0.31573;Gen: -3.86969;fit arb:  0.07124;lr: 0.00100;no_improve: 476
Epoch 9000 Loss: -0.33545;Gen: -3.85911;fit arb:  0.05046;lr: 0.00050;no_improve: 1476
Epoch 10000 Loss: -0.34377;Gen: -3.88356;fit arb:  0.04459;lr: 0.00050;no_improve: 2476
Epoch 11000 Loss: -0.34252;Gen: -3.89483;fit arb:  0.04696;lr: 0.00050;no_improve: 3476
Restart!Epoch 11524 Loss: -0.35099;Gen: -3.88361;fit arb:  0.03737;lr: 0.00100;no_improve: 0
Epoch 12000 Loss: -0.33945;Gen: -3.86031;fit arb:  0.04658;lr: 0.00100;no_improve: 476
Epoch 13000 Loss: -0.35415;Gen: -3.90941;fit arb:  0.03679;lr: 0.00050;no_improve: 1476
Epoch 14000 Loss: -0.34957;Gen: -3.85719;fit arb:  0.03615;lr: 0.00050;no_improve: 2476
Save!Epoch 14084 Loss: -0.36659;Gen: -3.93203;fit arb:  0.02661;lr: 0.00050; no_improve: 2559
Save!Epoch 14594 Loss: -0.36353;Gen: -3.88599;fit arb:  0.02507;lr: 0.00025; no_improve: 509
Save!Epoch 14595 Loss: -0.36826;Gen: -3.91049;fit arb:  0.02279;lr: 0.00025; no_improve: 0
Epoch 15000 Loss: -0.35807;Gen: -3.82871;fit arb:  0.02480;lr: 0.00025;no_improve: 405
Save!Epoch 15586 Loss: -0.36633;Gen: -3.87861;fit arb:  0.02153;lr: 0.00025; no_improve: 990
Epoch 16000 Loss: -0.35984;Gen: -3.86042;fit arb:  0.02620;lr: 0.00025;no_improve: 414
Save!Epoch 16140 Loss: -0.37105;Gen: -3.92365;fit arb:  0.02132;lr: 0.00025; no_improve: 553
Save!Epoch 16787 Loss: -0.36506;Gen: -3.85609;fit arb:  0.02055;lr: 0.00025; no_improve: 646
Epoch 17000 Loss: -0.36245;Gen: -3.91839;fit arb:  0.02938;lr: 0.00025;no_improve: 213
Epoch 18000 Loss: -0.36376;Gen: -3.91251;fit arb:  0.02749;lr: 0.00025;no_improve: 1213
Epoch 19000 Loss: -0.36741;Gen: -3.89890;fit arb:  0.02248;lr: 0.00025;no_improve: 2213
Epoch 20000 Loss: -0.36258;Gen: -3.91421;fit arb:  0.02884;lr: 0.00025;no_improve: 3213

训练完成! 分钟: 2025-08-27 11:20:00, 划分方式: forecast

==========================================
训练结束时间: 2025-10-19 09:28:21
==========================================
