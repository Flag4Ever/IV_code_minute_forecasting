==========================================
训练开始时间: 2025-10-19 08:14:54
分钟: 2025-08-25 13:30:00 | 划分: forecast | 设备: cuda
标记列: train_flag_inter
==========================================
加载数据: ../data/hushen300_minute/hushen300_minute.csv
筛选分钟: 2025-08-25 13:30:00
筛选后数据行数: 137
按照 train_flag_inter=1 筛选后数据行数: 137
加载初始化模型: ./checkpoint/know_forecast_all/hushen300_minute_forecast_clear/init_model/seed_1234_0.1_lr_0.001_gen_lr_0.001_w_d_0.0_best_model.pth
使用 torch.compile 优化模型 (设备: cuda)
/home/douxueli/miniconda3/envs/iv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
/home/douxueli/miniconda3/envs/iv/lib/python3.11/site-packages/torch/_inductor/compile_fx.py:140: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/home/douxueli/miniconda3/envs/iv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Glow模型使用 CUDA
加载Glow模型: ../glow_nn_line/glow_nn_svi_2/model_500000.pt
使用 torch.compile 优化 Glow 模型
开始训练，总轮数: 20000, 第一阶段: 0
Save!Epoch 2 Loss: -0.16432;Gen: -3.18513;fit arb:  0.15419;lr: 0.00100; no_improve: 1
Save!Epoch 3 Loss: -0.18927;Gen: -3.30849;fit arb:  0.14158;lr: 0.00100; no_improve: 0
Save!Epoch 4 Loss: -0.20023;Gen: -3.34801;fit arb:  0.13457;lr: 0.00100; no_improve: 0
Save!Epoch 5 Loss: -0.21416;Gen: -3.43992;fit arb:  0.12983;lr: 0.00100; no_improve: 0
Save!Epoch 9 Loss: -0.23796;Gen: -3.61899;fit arb:  0.12394;lr: 0.00100; no_improve: 3
Save!Epoch 10 Loss: -0.24990;Gen: -3.59013;fit arb:  0.10911;lr: 0.00100; no_improve: 0
Save!Epoch 11 Loss: -0.27691;Gen: -3.70079;fit arb:  0.09317;lr: 0.00100; no_improve: 0
Save!Epoch 12 Loss: -0.28883;Gen: -3.70706;fit arb:  0.08188;lr: 0.00100; no_improve: 0
Save!Epoch 30 Loss: -0.30044;Gen: -3.79053;fit arb:  0.07861;lr: 0.00100; no_improve: 17
Save!Epoch 31 Loss: -0.31633;Gen: -3.83103;fit arb:  0.06677;lr: 0.00100; no_improve: 0
Save!Epoch 32 Loss: -0.30845;Gen: -3.72825;fit arb:  0.06438;lr: 0.00100; no_improve: 0
Save!Epoch 42 Loss: -0.31604;Gen: -3.78056;fit arb:  0.06202;lr: 0.00100; no_improve: 9
Save!Epoch 52 Loss: -0.32500;Gen: -3.84263;fit arb:  0.05927;lr: 0.00100; no_improve: 9
Save!Epoch 62 Loss: -0.32242;Gen: -3.72245;fit arb:  0.04982;lr: 0.00100; no_improve: 9
Save!Epoch 72 Loss: -0.33027;Gen: -3.78526;fit arb:  0.04826;lr: 0.00100; no_improve: 9
Save!Epoch 82 Loss: -0.33640;Gen: -3.83162;fit arb:  0.04677;lr: 0.00100; no_improve: 9
Epoch 1000 Loss: -0.32572;Gen: -3.84352;fit arb:  0.05864;lr: 0.00050;no_improve: 918
Save!Epoch 1368 Loss: -0.33964;Gen: -3.84937;fit arb:  0.04529;lr: 0.00050; no_improve: 1285
Save!Epoch 1425 Loss: -0.34298;Gen: -3.87137;fit arb:  0.04415;lr: 0.00050; no_improve: 56
Save!Epoch 1553 Loss: -0.33969;Gen: -3.82953;fit arb:  0.04326;lr: 0.00050; no_improve: 127
Save!Epoch 1554 Loss: -0.34371;Gen: -3.86480;fit arb:  0.04277;lr: 0.00050; no_improve: 0
Save!Epoch 1590 Loss: -0.34306;Gen: -3.85182;fit arb:  0.04212;lr: 0.00050; no_improve: 35
Save!Epoch 1756 Loss: -0.34289;Gen: -3.84011;fit arb:  0.04112;lr: 0.00050; no_improve: 165
Save!Epoch 1886 Loss: -0.34907;Gen: -3.86437;fit arb:  0.03737;lr: 0.00050; no_improve: 129
Epoch 2000 Loss: -0.34081;Gen: -3.83287;fit arb:  0.04248;lr: 0.00050;no_improve: 114
Save!Epoch 2188 Loss: -0.35840;Gen: -3.94591;fit arb:  0.03619;lr: 0.00050; no_improve: 301
Save!Epoch 2601 Loss: -0.35274;Gen: -3.88537;fit arb:  0.03580;lr: 0.00050; no_improve: 412
Save!Epoch 2602 Loss: -0.35155;Gen: -3.86242;fit arb:  0.03469;lr: 0.00050; no_improve: 0
Save!Epoch 2697 Loss: -0.35356;Gen: -3.87451;fit arb:  0.03389;lr: 0.00025; no_improve: 94
Save!Epoch 2698 Loss: -0.35484;Gen: -3.86512;fit arb:  0.03167;lr: 0.00025; no_improve: 0
Save!Epoch 2740 Loss: -0.35902;Gen: -3.90335;fit arb:  0.03132;lr: 0.00025; no_improve: 41
Save!Epoch 2741 Loss: -0.36069;Gen: -3.90458;fit arb:  0.02977;lr: 0.00025; no_improve: 0
Save!Epoch 2802 Loss: -0.36268;Gen: -3.92142;fit arb:  0.02946;lr: 0.00025; no_improve: 60
Save!Epoch 2905 Loss: -0.35811;Gen: -3.86629;fit arb:  0.02852;lr: 0.00025; no_improve: 102
Epoch 3000 Loss: -0.35006;Gen: -3.88891;fit arb:  0.03883;lr: 0.00025;no_improve: 95
Save!Epoch 3006 Loss: -0.36001;Gen: -3.87424;fit arb:  0.02741;lr: 0.00025; no_improve: 100
Save!Epoch 3045 Loss: -0.35656;Gen: -3.83001;fit arb:  0.02644;lr: 0.00025; no_improve: 38
Save!Epoch 3165 Loss: -0.36207;Gen: -3.86483;fit arb:  0.02442;lr: 0.00025; no_improve: 119
Epoch 4000 Loss: -0.36235;Gen: -3.91523;fit arb:  0.02917;lr: 0.00025;no_improve: 835
Epoch 5000 Loss: -0.35479;Gen: -3.87409;fit arb:  0.03262;lr: 0.00025;no_improve: 1835
Save!Epoch 5189 Loss: -0.36531;Gen: -3.89135;fit arb:  0.02383;lr: 0.00025; no_improve: 2023
Save!Epoch 5305 Loss: -0.36570;Gen: -3.88850;fit arb:  0.02315;lr: 0.00025; no_improve: 115
Epoch 6000 Loss: -0.36244;Gen: -3.91487;fit arb:  0.02905;lr: 0.00025;no_improve: 695
Save!Epoch 6408 Loss: -0.36429;Gen: -3.87045;fit arb:  0.02275;lr: 0.00025; no_improve: 1102
Save!Epoch 6725 Loss: -0.36717;Gen: -3.89595;fit arb:  0.02243;lr: 0.00025; no_improve: 316
Epoch 7000 Loss: -0.36411;Gen: -3.88763;fit arb:  0.02465;lr: 0.00025;no_improve: 275
Save!Epoch 7315 Loss: -0.36650;Gen: -3.88535;fit arb:  0.02204;lr: 0.00025; no_improve: 589
Save!Epoch 7316 Loss: -0.36905;Gen: -3.90843;fit arb:  0.02179;lr: 0.00025; no_improve: 0
Epoch 8000 Loss: -0.36058;Gen: -3.93533;fit arb:  0.03296;lr: 0.00025;no_improve: 684
Save!Epoch 8612 Loss: -0.36992;Gen: -3.91408;fit arb:  0.02148;lr: 0.00025; no_improve: 1295
Epoch 9000 Loss: -0.36664;Gen: -3.90792;fit arb:  0.02416;lr: 0.00025;no_improve: 388
Save!Epoch 9089 Loss: -0.36974;Gen: -3.90615;fit arb:  0.02088;lr: 0.00025; no_improve: 476
Epoch 10000 Loss: -0.36653;Gen: -3.91189;fit arb:  0.02466;lr: 0.00025;no_improve: 911
Save!Epoch 10354 Loss: -0.37338;Gen: -3.93875;fit arb:  0.02050;lr: 0.00025; no_improve: 1264
Save!Epoch 10745 Loss: -0.36906;Gen: -3.89214;fit arb:  0.02016;lr: 0.00025; no_improve: 390
Epoch 11000 Loss: -0.36737;Gen: -3.92733;fit arb:  0.02536;lr: 0.00025;no_improve: 255
Epoch 12000 Loss: -0.36245;Gen: -3.90305;fit arb:  0.02786;lr: 0.00025;no_improve: 1255
Epoch 13000 Loss: -0.36552;Gen: -3.92853;fit arb:  0.02734;lr: 0.00025;no_improve: 2255
Epoch 14000 Loss: -0.36423;Gen: -3.86170;fit arb:  0.02194;lr: 0.00025;no_improve: 3255
Restart!Epoch 14745 Loss: -0.36893;Gen: -3.91133;fit arb:  0.02220;lr: 0.00100;no_improve: 0
Epoch 15000 Loss: -0.33958;Gen: -3.81791;fit arb:  0.04222;lr: 0.00100;no_improve: 255
Epoch 16000 Loss: -0.36079;Gen: -3.85477;fit arb:  0.02469;lr: 0.00025;no_improve: 1255
Epoch 17000 Loss: -0.36959;Gen: -3.91217;fit arb:  0.02162;lr: 0.00025;no_improve: 2255
Epoch 18000 Loss: -0.36790;Gen: -3.91450;fit arb:  0.02355;lr: 0.00025;no_improve: 3255
Restart!Epoch 18745 Loss: -0.36128;Gen: -3.90045;fit arb:  0.02877;lr: 0.00100;no_improve: 0
Epoch 19000 Loss: -0.33775;Gen: -3.89110;fit arb:  0.05136;lr: 0.00100;no_improve: 255
Epoch 20000 Loss: -0.35485;Gen: -3.88707;fit arb:  0.03386;lr: 0.00050;no_improve: 1255

训练完成! 分钟: 2025-08-25 13:30:00, 划分方式: forecast

==========================================
训练结束时间: 2025-10-19 08:23:34
==========================================
