==========================================
训练开始时间: 2025-10-18 16:17:59
分钟: 2025-08-11 09:30:00 | 划分: forecast | 设备: cuda
标记列: train_flag_inter
==========================================
使用设备: CUDA (NVIDIA GeForce RTX 4090)
加载数据: ../data/hushen300_minute/hushen300_minute.csv
筛选分钟: 2025-08-11 09:30:00
筛选后数据行数: 120
按照 train_flag_inter=1 筛选后数据行数: 120
使用 torch.compile 优化模型 (设备: cuda)
/home/douxueli/miniconda3/envs/iv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
开始训练，总轮数: 10000, Restart次数: 4
Saved! Epoch 1 Loss:  0.32869;lr: 0.01000
Saved! Epoch 2 Loss:  0.22832;lr: 0.01000
Saved! Epoch 3 Loss:  0.18859;lr: 0.01000
Saved! Epoch 7 Loss:  0.16515;lr: 0.01000
Saved! Epoch 10 Loss:  0.15314;lr: 0.01000
Saved! Epoch 14 Loss:  0.14112;lr: 0.01000
Saved! Epoch 16 Loss:  0.13509;lr: 0.01000
Saved! Epoch 19 Loss:  0.12604;lr: 0.01000
Saved! Epoch 25 Loss:  0.12204;lr: 0.01000
Saved! Epoch 43 Loss:  0.12063;lr: 0.01000
Saved! Epoch 47 Loss:  0.11929;lr: 0.01000
Saved! Epoch 51 Loss:  0.11766;lr: 0.01000
Saved! Epoch 55 Loss:  0.11633;lr: 0.01000
Saved! Epoch 61 Loss:  0.11473;lr: 0.01000
Saved! Epoch 67 Loss:  0.11316;lr: 0.01000
Saved! Epoch 75 Loss:  0.11172;lr: 0.01000
Saved! Epoch 81 Loss:  0.10908;lr: 0.01000
Saved! Epoch 91 Loss:  0.10776;lr: 0.01000
Saved! Epoch 99 Loss:  0.10581;lr: 0.01000
Saved! Epoch 109 Loss:  0.10452;lr: 0.01000
Saved! Epoch 118 Loss:  0.10329;lr: 0.01000
Saved! Epoch 126 Loss:  0.10223;lr: 0.01000
Saved! Epoch 140 Loss:  0.10084;lr: 0.01000
Saved! Epoch 157 Loss:  0.09918;lr: 0.01000
Saved! Epoch 165 Loss:  0.09810;lr: 0.01000
Saved! Epoch 174 Loss:  0.09692;lr: 0.01000
Saved! Epoch 184 Loss:  0.09582;lr: 0.01000
Saved! Epoch 194 Loss:  0.09483;lr: 0.01000
Saved! Epoch 206 Loss:  0.09365;lr: 0.01000
Saved! Epoch 221 Loss:  0.09265;lr: 0.01000
Saved! Epoch 235 Loss:  0.09166;lr: 0.01000
Saved! Epoch 248 Loss:  0.09058;lr: 0.01000
Saved! Epoch 285 Loss:  0.08939;lr: 0.01000
Saved! Epoch 311 Loss:  0.08841;lr: 0.01000
Saved! Epoch 333 Loss:  0.08745;lr: 0.01000
Saved! Epoch 400 Loss:  0.08646;lr: 0.01000
Saved! Epoch 478 Loss:  0.08557;lr: 0.01000
Saved! Epoch 976 Loss:  0.08462;lr: 0.01000
Saved! Epoch 2000 Loss:  0.08430;lr: 0.00250
Restart!Epoch 976 Loss:  0.08423;lr: 0.01000
Saved! Epoch 2000 Loss:  0.08447;lr: 0.00250
Restart!Epoch 976 Loss:  0.08426;lr: 0.01000
Saved! Epoch 2000 Loss:  0.08447;lr: 0.00250
Restart!Epoch 976 Loss:  0.08426;lr: 0.01000
Saved! Epoch 2000 Loss:  0.08447;lr: 0.00250
Restart!Epoch 976 Loss:  0.08426;lr: 0.01000
Saved! Epoch 2000 Loss:  0.08447;lr: 0.00250
Saved! Epoch 4000 Loss:  0.08411;lr: 0.00016
Saved! Epoch 6000 Loss:  0.08408;lr: 0.00001
Saved! Epoch 8000 Loss:  0.08407;lr: 0.00001
Saved! Epoch 10000 Loss:  0.08407;lr: 0.00001

训练完成! 分钟: 2025-08-11 09:30:00, 划分方式: forecast

==========================================
训练结束时间: 2025-10-18 16:20:54
==========================================
