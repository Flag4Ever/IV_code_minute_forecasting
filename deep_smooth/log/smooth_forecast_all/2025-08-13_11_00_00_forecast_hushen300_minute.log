==========================================
训练开始时间: 2025-10-18 16:43:58
分钟: 2025-08-13 11:00:00 | 划分: forecast | 设备: cuda
标记列: train_flag_inter
==========================================
使用设备: CUDA (NVIDIA GeForce RTX 4090)
加载数据: ../data/hushen300_minute/hushen300_minute.csv
筛选分钟: 2025-08-13 11:00:00
筛选后数据行数: 120
按照 train_flag_inter=1 筛选后数据行数: 120
使用 torch.compile 优化模型 (设备: cuda)
/home/douxueli/miniconda3/envs/iv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
开始训练，总轮数: 10000, Restart次数: 4
Saved! Epoch 1 Loss:  0.40169;lr: 0.01000
Saved! Epoch 2 Loss:  0.28815;lr: 0.01000
Saved! Epoch 3 Loss:  0.26300;lr: 0.01000
Saved! Epoch 6 Loss:  0.24725;lr: 0.01000
Saved! Epoch 7 Loss:  0.24275;lr: 0.01000
Saved! Epoch 9 Loss:  0.22107;lr: 0.01000
Saved! Epoch 12 Loss:  0.21104;lr: 0.01000
Saved! Epoch 15 Loss:  0.19756;lr: 0.01000
Saved! Epoch 18 Loss:  0.18842;lr: 0.01000
Saved! Epoch 21 Loss:  0.18474;lr: 0.01000
Saved! Epoch 24 Loss:  0.18173;lr: 0.01000
Saved! Epoch 29 Loss:  0.17970;lr: 0.01000
Saved! Epoch 37 Loss:  0.17743;lr: 0.01000
Saved! Epoch 46 Loss:  0.17541;lr: 0.01000
Saved! Epoch 52 Loss:  0.17359;lr: 0.01000
Saved! Epoch 57 Loss:  0.17182;lr: 0.01000
Saved! Epoch 63 Loss:  0.17004;lr: 0.01000
Saved! Epoch 69 Loss:  0.16829;lr: 0.01000
Saved! Epoch 74 Loss:  0.16645;lr: 0.01000
Saved! Epoch 78 Loss:  0.16464;lr: 0.01000
Saved! Epoch 82 Loss:  0.16226;lr: 0.01000
Saved! Epoch 89 Loss:  0.16061;lr: 0.01000
Saved! Epoch 93 Loss:  0.15900;lr: 0.01000
Saved! Epoch 103 Loss:  0.15700;lr: 0.01000
Saved! Epoch 109 Loss:  0.15523;lr: 0.01000
Saved! Epoch 116 Loss:  0.15352;lr: 0.01000
Saved! Epoch 123 Loss:  0.15190;lr: 0.01000
Saved! Epoch 132 Loss:  0.15003;lr: 0.01000
Saved! Epoch 142 Loss:  0.14833;lr: 0.01000
Saved! Epoch 149 Loss:  0.14680;lr: 0.01000
Saved! Epoch 158 Loss:  0.14522;lr: 0.01000
Saved! Epoch 169 Loss:  0.14359;lr: 0.01000
Saved! Epoch 180 Loss:  0.14207;lr: 0.01000
Saved! Epoch 191 Loss:  0.14059;lr: 0.01000
Saved! Epoch 208 Loss:  0.13856;lr: 0.01000
Saved! Epoch 233 Loss:  0.13706;lr: 0.01000
Saved! Epoch 259 Loss:  0.13566;lr: 0.01000
Saved! Epoch 298 Loss:  0.13426;lr: 0.01000
Saved! Epoch 328 Loss:  0.13271;lr: 0.01000
Saved! Epoch 422 Loss:  0.13125;lr: 0.01000
Saved! Epoch 573 Loss:  0.12982;lr: 0.01000
Saved! Epoch 1103 Loss:  0.12851;lr: 0.00500
Saved! Epoch 2000 Loss:  0.12784;lr: 0.00250
Saved! Epoch 2411 Loss:  0.12721;lr: 0.00125
Saved! Epoch 2829 Loss:  0.12593;lr: 0.00125
Saved! Epoch 2982 Loss:  0.12465;lr: 0.00125
Saved! Epoch 3079 Loss:  0.12336;lr: 0.00125
Saved! Epoch 3151 Loss:  0.12201;lr: 0.00125
Saved! Epoch 3215 Loss:  0.12077;lr: 0.00125
Saved! Epoch 3293 Loss:  0.11951;lr: 0.00125
Saved! Epoch 3394 Loss:  0.11821;lr: 0.00125
Saved! Epoch 3516 Loss:  0.11689;lr: 0.00125
Saved! Epoch 3645 Loss:  0.11567;lr: 0.00125
Saved! Epoch 3771 Loss:  0.11449;lr: 0.00125
Saved! Epoch 3889 Loss:  0.11324;lr: 0.00125
Saved! Epoch 3980 Loss:  0.11203;lr: 0.00125
Saved! Epoch 4000 Loss:  0.11194;lr: 0.00125
Saved! Epoch 4062 Loss:  0.11088;lr: 0.00125
Saved! Epoch 4121 Loss:  0.10975;lr: 0.00125
Saved! Epoch 4174 Loss:  0.10853;lr: 0.00125
Saved! Epoch 4226 Loss:  0.10739;lr: 0.00125
Saved! Epoch 4278 Loss:  0.10628;lr: 0.00125
Saved! Epoch 4347 Loss:  0.10517;lr: 0.00125
Saved! Epoch 4421 Loss:  0.10406;lr: 0.00125
Saved! Epoch 4495 Loss:  0.10287;lr: 0.00125
Saved! Epoch 4558 Loss:  0.10178;lr: 0.00125
Saved! Epoch 4620 Loss:  0.10068;lr: 0.00125
Saved! Epoch 4674 Loss:  0.09963;lr: 0.00125
Saved! Epoch 4722 Loss:  0.09863;lr: 0.00125
Saved! Epoch 4775 Loss:  0.09761;lr: 0.00125
Saved! Epoch 4827 Loss:  0.09660;lr: 0.00125
Saved! Epoch 4880 Loss:  0.09557;lr: 0.00125
Saved! Epoch 4943 Loss:  0.09460;lr: 0.00125
Saved! Epoch 4997 Loss:  0.09360;lr: 0.00125
Saved! Epoch 5061 Loss:  0.09265;lr: 0.00125
Saved! Epoch 5128 Loss:  0.09172;lr: 0.00125
Saved! Epoch 5197 Loss:  0.09077;lr: 0.00125
Saved! Epoch 5273 Loss:  0.08980;lr: 0.00125
Saved! Epoch 5359 Loss:  0.08889;lr: 0.00125
Saved! Epoch 5446 Loss:  0.08792;lr: 0.00125
Saved! Epoch 5554 Loss:  0.08704;lr: 0.00125
Saved! Epoch 5670 Loss:  0.08611;lr: 0.00125
Saved! Epoch 5813 Loss:  0.08519;lr: 0.00125
Saved! Epoch 5926 Loss:  0.08432;lr: 0.00125
Saved! Epoch 6000 Loss:  0.08397;lr: 0.00125
Saved! Epoch 6063 Loss:  0.08346;lr: 0.00125
Saved! Epoch 6228 Loss:  0.08258;lr: 0.00125
Saved! Epoch 6412 Loss:  0.08169;lr: 0.00125
Saved! Epoch 6604 Loss:  0.08081;lr: 0.00125
Saved! Epoch 6826 Loss:  0.07997;lr: 0.00125
Saved! Epoch 6998 Loss:  0.07914;lr: 0.00125
Saved! Epoch 7105 Loss:  0.07834;lr: 0.00125
Saved! Epoch 7215 Loss:  0.07755;lr: 0.00125
Saved! Epoch 7330 Loss:  0.07673;lr: 0.00125
Saved! Epoch 7471 Loss:  0.07593;lr: 0.00125
Saved! Epoch 7622 Loss:  0.07513;lr: 0.00125
Saved! Epoch 7787 Loss:  0.07438;lr: 0.00125
Saved! Epoch 8000 Loss:  0.07407;lr: 0.00125
Saved! Epoch 8068 Loss:  0.07363;lr: 0.00125
Saved! Epoch 8606 Loss:  0.07289;lr: 0.00063
Saved! Epoch 10000 Loss:  0.07255;lr: 0.00016

训练完成! 分钟: 2025-08-13 11:00:00, 划分方式: forecast

==========================================
训练结束时间: 2025-10-18 16:45:47
==========================================
